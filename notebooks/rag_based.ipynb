{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Photon, Nominatim\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/quamer23nasim38/reverse-recommendation-for-anomaly-detection/'\n",
    "data_path = 'data/fraudTrain.csv'\n",
    "\n",
    "max_user = 5\n",
    "convert_coordinates_to_address = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dob_to_age(dob_str):\n",
    "    \"\"\"\n",
    "    Converts date of birth (dob) in 'YYYY-MM-DD' format to age in years.\n",
    "    \n",
    "    Args:\n",
    "        dob_str (str): Date of birth in 'YYYY-MM-DD' format.\n",
    "    \n",
    "    Returns:\n",
    "        int: Age in years.\n",
    "    \"\"\"\n",
    "    # Convert the dob_str into a datetime object\n",
    "    dob = datetime.strptime(dob_str, '%Y-%m-%d')\n",
    "    \n",
    "    # Get the current date\n",
    "    today = datetime.today()\n",
    "    \n",
    "    # Calculate age\n",
    "    age = today.year - dob.year\n",
    "    \n",
    "    # Adjust age if birthday hasn't occurred yet this year\n",
    "    if (today.month, today.day) < (dob.month, dob.day):\n",
    "        age -= 1\n",
    "    \n",
    "    return age\n",
    "\n",
    "def lat_long_to_address(lat, long):\n",
    "    \"\"\"\n",
    "    Converts latitude and longitude to an address using Geopy.\n",
    "    \n",
    "    Args:\n",
    "        lat (float): Latitude value.\n",
    "        long (float): Longitude value.\n",
    "    \n",
    "    Returns:\n",
    "        str: Corresponding address.\n",
    "    \"\"\"\n",
    "    photon, nominatim = False, False\n",
    "    try:\n",
    "        GEOLOCATOR = Photon(user_agent=\"measurements\")\n",
    "        location = GEOLOCATOR.reverse((lat, long), language='en')\n",
    "        photon = True\n",
    "    except:\n",
    "        try:\n",
    "            GEOLOCATOR = Nominatim(user_agent=\"measurements\")\n",
    "            location = GEOLOCATOR.reverse((lat, long), language='en')\n",
    "            nominatim = True\n",
    "        except:\n",
    "            return None\n",
    "    if location:\n",
    "        if photon:\n",
    "            properties = location.raw['properties']\n",
    "        elif nominatim:\n",
    "            properties = location.raw['address']\n",
    "        if properties.get('extent'):\n",
    "            del properties['extent']\n",
    "\n",
    "        if properties.get('osm_id'):\n",
    "            del properties['osm_id']\n",
    "        return properties\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def convert_transaction_data_to_str(transaction_information, merchant_information, payment_address, merchant_address):\n",
    "    template = f'''\n",
    "{transaction_information['amt']}\n",
    "-----------------------\n",
    "{merchant_information['merchant']}; {merchant_information['category']}\n",
    "-----------------------\n",
    "{payment_address}\n",
    "-----------------------\n",
    "{merchant_address}\n",
    "'''\n",
    "    return template\n",
    "\n",
    "def get_user_basic_info(transaction_detail):\n",
    "    customer_information = transaction_detail[['name', 'gender', 'job', 'age']]\n",
    "    registered_address = transaction_detail[['street', 'city', 'state', 'zip']]\n",
    "    return customer_information, registered_address\n",
    "\n",
    "def get_transactional_data(transaction_detail, convert_coordinates_to_address=True):\n",
    "    transaction_information = transaction_detail[['trans_date_trans_time', 'amt']]\n",
    "    merchant_information = transaction_detail[['merchant', 'category']]\n",
    "\n",
    "    payment_lat, payment_long = transaction_detail[['lat', 'long']].values\n",
    "    if convert_coordinates_to_address:\n",
    "        payment_address = lat_long_to_address(payment_lat, payment_long)\n",
    "    else:\n",
    "        payment_address = None\n",
    "    if payment_address:\n",
    "        payment_address.update({'lat': payment_lat, 'long': payment_long})\n",
    "    else:\n",
    "        payment_address = {'lat': payment_lat, 'long': payment_long}\n",
    "    payment_address = '; '.join([str(v) for _, v in payment_address.items()])\n",
    "\n",
    "    merchant_lat, merchant_long = transaction_detail[['merch_lat', 'merch_long']].values\n",
    "    if convert_coordinates_to_address:\n",
    "        merchant_address = lat_long_to_address(merchant_lat, merchant_long)\n",
    "    else:\n",
    "        merchant_address = None\n",
    "    if merchant_address:\n",
    "        merchant_address.update({'lat': merchant_lat, 'long': merchant_long})\n",
    "    else:\n",
    "        merchant_address = {'lat': merchant_lat, 'long': merchant_long}\n",
    "    merchant_address = '; '.join([str(v) for _, v in merchant_address.items()])\n",
    "    \n",
    "    return transaction_information, merchant_information, payment_address, merchant_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(pjoin(root, data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cc_num = random.sample(list(df['cc_num'].unique()), max_user)\n",
    "filtered_data = df[df['cc_num'].isin(random_cc_num)]\n",
    "data = filtered_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['age'] = data['dob'].map(dob_to_age)\n",
    "data.gender = data.gender.replace({\n",
    "    'F': 'Female',\n",
    "    'M': 'Male'\n",
    "})\n",
    "data['name'] = data['first'] + ' ' + data['last']\n",
    "data['merchant'] = data.merchant.str.replace('fraud_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained model (e.g., Sentence-BERT)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-small-en\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-small-en\")\n",
    "model.eval()\n",
    "\n",
    "# Function to create embeddings from a transaction description\n",
    "def embed_transaction(description):\n",
    "    inputs = tokenizer(description, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs)\n",
    "        embeddings = embeddings[0][:, 0]\n",
    "    embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "# Initialize in-memory Qdrant client\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection in Qdrant for storing transaction embeddings\n",
    "client.create_collection(\n",
    "    collection_name=\"transactions\",\n",
    "    vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n",
    ")\n",
    "\n",
    "def insert_transaction(transaction_embedding, payload, idx):\n",
    "\n",
    "    client.upsert(\n",
    "        collection_name=\"transactions\",\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=idx,\n",
    "                payload={\n",
    "                    \"transaction_data\": payload,\n",
    "                },\n",
    "                vector=transaction_embedding,\n",
    "            ),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508\n"
     ]
    }
   ],
   "source": [
    "for user in random_cc_num:\n",
    "    user_data = data[data['cc_num'] == user]\n",
    "    user_data = user_data[user_data['is_fraud'] == 0]\n",
    "    if user_data.shape[0]>0:\n",
    "        customer_information, registered_address = get_user_basic_info(user_data.iloc[0])\n",
    "        print(user_data.shape[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 100/508 [05:02<20:35,  3.03s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx, (_, transaction) in tqdm(enumerate(user_data.iterrows()), total=len(user_data)):\n",
    "    transaction_information, merchant_information, payment_address, merchant_address = get_transactional_data(transaction, convert_coordinates_to_address=True)\n",
    "    transaction_description = convert_transaction_data_to_str(transaction_information, merchant_information, payment_address, merchant_address)\n",
    "    embedding = embed_transaction(transaction_description)\n",
    "    embedding = embedding[0].tolist()\n",
    "    insert_transaction(embedding, transaction_description, idx)\n",
    "    time.sleep(1)\n",
    "    if idx == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transaction_info = '''\n",
    "420000.54\n",
    "-----------------------\n",
    "Rajesh, Kumar; savings_account\n",
    "-----------------------\n",
    "Chandini Chowk; Delhi; India; 20.0583; 16.008\n",
    "-----------------------\n",
    "Vietnaam; 20.152538; 16.227746\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding = embed_transaction(new_transaction_info)\n",
    "\n",
    "results = client.query_points(\n",
    "    collection_name=\"transactions\",\n",
    "    query=new_embedding[0].tolist(),\n",
    "    limit=10,\n",
    ").points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(query_response, threshold=0.95):\n",
    "    similarity_scores = []\n",
    "    for result in query_response:\n",
    "        similarity_scores.append(result.score)\n",
    "\n",
    "    if np.mean(similarity_scores) < threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_anomalies(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = []\n",
    "for res in results:\n",
    "    context.append(res.payload['transaction_data'])\n",
    "context = \"\\n=============================NEW EXAMPLE===================================\\n\".join(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You're an intelligent AI assistant that helps in detecting fraudulent transactions. \n",
    "\n",
    "You're provided with the three key information:\n",
    "    1. CUSTOMER INFORMATION: This has all the basic information about the customer which should give some idea about customer behaviour. The template is provided below.\n",
    "    2. CONTEXT: This has several  examples of a normal and non-fraudulent transactional information for the user. The template for each transaction is provided below.\n",
    "    3. NEW TRANSACTIONAL INFORMATION: This is the new transactional information that you need to classify as fraudulent or not. The template is same as normal transactional information \n",
    "\n",
    "Template for CUSTOMER INFORMATION and TRANSACTIONAL INFORMATION are provided below:\n",
    "    1. CUSTOMER INFORMATION TEMPLATE\n",
    "        {NAME}; {GENDER}; {AGE}; {JOB}\n",
    "        -----------------------\n",
    "        {REGISTERED ADDRESS}\n",
    "\n",
    "    2. TRANSACTIONAL INFORMATION TEMPLATE: \n",
    "        {AMOUNT}\n",
    "        -----------------------\n",
    "        {MERCHANT NAME}; {CATEGORY}\n",
    "        -----------------------\n",
    "        {PAYMENT ADDRESS}\n",
    "        -----------------------\n",
    "        {MERCHANT ADDRESS} \n",
    "\n",
    "Your task is to uderstand USER's personal information, registered address, and examples of normal transactional information based on template provided and classify the new transactional information as fraudulent or not based on the context provided and also provide the reason for your classification.\n",
    "\n",
    "You're only allowed to provide response in a json format with the following keys:\n",
    "    1. classification: This should be either of the following:\n",
    "        a. Fraudulent\n",
    "        b. Non-Fraudulent\n",
    "    2. reason: This should be a string explaining the reason for your classification.\n",
    "\n",
    "Example of the response:\n",
    "{\n",
    "    \"classification\": \"Fraudulent\",\n",
    "    \"reason\": \"The transaction amount is significantly higher than the average transaction amount.\"\n",
    "}\n",
    "    \n",
    "You can not provide any other response apart from the above mentioned json format with the keys mentioned above. In the classification key, you can only provide either \"Fraudulent\" or \"Non-Fraudulent\" as the value.\n",
    "'''\n",
    "\n",
    "prompt_template = f'''\n",
    "1. CUSTOMER INFORMATION:\n",
    "    {customer_information['name']}; {customer_information['gender']}; {customer_information['age']}; {customer_information['job']}\n",
    "    -----------------------\n",
    "    {registered_address['street']}; {registered_address['city']}; {registered_address['state']}; {registered_address['zip']}\n",
    "\n",
    "2. CONTEXT:\n",
    "    {context}\n",
    "\n",
    "3. NEW TRANSACTIONAL INFORMATION:\n",
    "    {new_transaction_info}\n",
    "\n",
    "RESPONSE:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012183666229248047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09263777f874baa8273d7e64d1ba156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quantization_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '{\\n    \"classification\": \"Fraudulent\",\\n    \"reason\": \"The transaction amount is significantly higher than the average transaction amount and the transaction is from a different country which is not present in the context.\"\\n}'}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt_template},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 'Fraudulent',\n",
       " 'reason': 'The transaction amount is significantly higher than the average transaction amount and the transaction is from a different country which is not present in the context.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(outputs[0][\"generated_text\"][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
